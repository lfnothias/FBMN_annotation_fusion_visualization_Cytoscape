{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v2J_vpilI5B5"
   },
   "source": [
    "# FBMN Annotation & Visualization in Cytoscape\n",
    "\n",
    "<details>\n",
    "    <summary>Click to view the narrative</summary>\n",
    "\n",
    "## Overall narrative of the workshop\n",
    "\n",
    "- import a network (GNPS or MSQuery) in Cytoscape\n",
    "\n",
    "- import the MZmine table for node metadata\n",
    "\n",
    "- import the IIMN edge table.\n",
    "\n",
    "- show the styling with ion identity network.\n",
    "\n",
    "- duplicate the views and rename the views for each tool.\n",
    "\n",
    "- explain requirements for further import (unique feature id, first column, smiles [name and ,] ). And opportunity for information-rich labeling for each tool. \n",
    "\n",
    "- import tool prepared tool output into the network.\n",
    "\n",
    "- bring-in styles (Get the Cytoscape style for each tool).\n",
    "\n",
    "- explore with each tool\n",
    "</details>\n",
    "\n",
    "## Let's go\n",
    "\n",
    "**Installation**: install Cytoscape [https://cytoscape.org/](https://cytoscape.org/) and its ChemViz2 pluggin [https://apps.cytoscape.org/apps/chemviz2](https://apps.cytoscape.org/apps/chemviz2).\n",
    "\n",
    "**Notebook**: the notebook is available at [https://github.com/lfnothias/FBMN_annotation_fusion_visualization_Cytoscape](https://github.com/lfnothias/FBMN_annotation_fusion_visualization_Cytoscape). It can run as a Binder instance (see link).\n",
    "\n",
    "**Input files**: the FBMN network and annotation files were uploaded to the github repo as of April 15th 2024. If needed, update them.\n",
    "\n",
    "## Step 1 - Import a network\n",
    "\n",
    "- Open Cytoscape and import a FBMN derived network file (graphml file). The process can be done by drag & drop or with `File / Import / Network from File`.\n",
    "\n",
    "- Demo about Cytoscape and key definitions (node table, edge table).\n",
    "\n",
    "- We observe the limited number of information available in the file.\n",
    "\n",
    "## Step 2 - Import a Node Table\n",
    "\n",
    "Node table contains metadata about nodes (a feature MS1/MS2 spectra) and are mapped with column containing the 'Feature_ID' (or its variant = ['scan',featureID', 'feature_id', ... ) on the 'shared name' column. Preferably on the first column of the node table (or select the mapping key accordingly). It must be unique. If columns are already present, they will be ovewritten.\n",
    "\n",
    "- We will import the `mzmine_results_iimn_gnps_quant.csv` into Cytoscape. First lets take a look at its content and comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "mzmine = 'results_download/mzmine/mzmine_results_iimn_gnps_quant.csv'\n",
    "pd.read_csv(mzmine).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets import it in Cytoscape \n",
    "\n",
    "- The node table import can be done with  `File / Import / Table from File`. \\\n",
    "Make sure you select the correct the right Network for import (Network Collection) and the correct Data Type (Node or Edge Table).\n",
    "\n",
    "- Start basic Node styling with the Style panel.\n",
    "\n",
    "## Step 3 - Import an Edge Table\n",
    "\n",
    "Edge table contains metadata about nodes (a feature MS1/MS2 spectra) and are mapped with column containing the interaction ID [NodeID1 (-) NodeID2) and named 'shared name'. Preferably on the first column of the node table (or select the mapping key accordingly). It must be unique. If columns are already present, they will be ovewritten.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare IIMN edges for Cytoscape\n",
    "\n",
    "We need to create a 'shared name' column in the edge table to streamline Cytoscape import.\n",
    "\n",
    "Original table:\n",
    "| ID1 | ID2 | EdgeType | Score | Annotation |\n",
    "|-----|-----|----------|-------|------------|\n",
    "| 36  | 37  | MS1 annotation | 2      | [M+K]+ [2M+Na]+ dm/z=299.18058           |\n",
    "\n",
    "Prepared table:\n",
    "| shared name | ID1 | ID2 | EdgeType | Score | Annotation |\n",
    "|-------------|-----|-----|----------|-------|------------|\n",
    "| 36 (-) 37   | 36  | 37  |MS1 annotation| 2      | [M+K]+ [2M+Na]+ dm/z=299.18058           |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_separator(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        first_line = file.readline()\n",
    "        if '\\t' in first_line:\n",
    "            return '\\t'\n",
    "        else:\n",
    "            return ','  # Default to comma if no tab found\n",
    "\n",
    "def prepare_fbmn_iimn_edge_annotation_cytoscape(input_file, output_suffix='_prep'):\n",
    "    # Load the CSV file into a DataFrame\n",
    "    separator = detect_separator(input_file)\n",
    "    df = pd.read_csv(input_file, sep=separator)\n",
    "\n",
    "    # Check if ID1 and ID2 are in the DataFrame\n",
    "    if 'ID1' not in df.columns or 'ID2' not in df.columns:\n",
    "        raise ValueError(\"ID1 or ID2 column is missing in the DataFrame.\")\n",
    "\n",
    "    # Create a new column 'ID1-ID2' by concatenating 'ID1' and 'ID2' with \" (-) \" in between\n",
    "    df['shared name'] = df['ID1'].astype(str) + ' (-) ' + df['ID2'].astype(str)\n",
    "\n",
    "    # Move the new column to the first position\n",
    "    cols = df.columns.tolist()\n",
    "    cols = ['shared name'] + [col for col in cols if col != 'shared name']\n",
    "    df = df[cols]\n",
    "\n",
    "    # Save the modified DataFrame to a new CSV file with the specified suffix\n",
    "    output_file = f\"{input_file.rsplit('.', 1)[0]}{output_suffix}.tsv\"\n",
    "    df.to_csv(output_file, index=False, sep='\\t')\n",
    "\n",
    "    # Print the new output file name\n",
    "    print(f\"File saved as: {output_file}\")\n",
    "    return df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iimn_edge_table_path = 'results_download/mzmine/mzmine_results_iimn_gnps_edges_msannotation.csv'\n",
    "prepare_fbmn_iimn_edge_annotation_cytoscape(iimn_edge_table_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the prepared IIMN Edge Table into Cytoscape\n",
    "\n",
    "- The node table import can be done with  `File / Import / Table from File`.\\\n",
    "Make sure you select the correct the right Network for import (Network Collection) and the correct Data Type (Node or Edge Table).\n",
    "\n",
    "- Start styling Edges with the Style panel. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Importing other annotations\n",
    "\n",
    "### MS2Query annotations\n",
    "\n",
    "Lets take a look at MS2Query table and import it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms2query_annotation_path = 'results_download/matchms/results_for_cytoscape/ms2query_results_for_cytoscape.csv'\n",
    "pd.read_csv(ms2query_annotation_path).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has the requirements for Cytoscape import on FBMN network !\n",
    "\n",
    "**Requirements**:\n",
    "- a `feature_id` column from the FBMN. The exact column naming is flexible. \n",
    "- the `feature_id` entries must be unique and consistent.\n",
    "\n",
    "    \n",
    "**Bonus to streamline Cytoscape**:\n",
    "- The `feature_id` column (or equivalent) should be the first column.\n",
    "- If there are structural annotations, the annotation name should be in a `name` column, the smiles should be in a `smiles` column.\n",
    "- We introduce a prefix for all the annotation columns.\n",
    "- We will add a 'annotation' tool column for visualization.\n",
    "\n",
    "\n",
    "Lets check the minimum requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms2query_annotation = pd.read_csv(ms2query_annotation_path)\n",
    "print(ms2query_annotation.columns)\n",
    "ms2query_annotation.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We check for uniqueness of feature_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for if feature_id is unique.\n",
    "print('Is feature_id unique ? = ' + str(ms2query_annotation['feature_id'].is_unique))\n",
    "\n",
    "# Lets rename the name and same\n",
    "ms2query_annotation['name'] = ms2query_annotation['analog_compound_name']\n",
    "ms2query_annotation.to_csv(ms2query_annotation_path[:-4]+'_prep.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets import it in Cytoscape\n",
    "\n",
    "- The node table import can be done with  `File / Import / Table from File`. \\\n",
    "Make sure you select the correct the right Network for import (Network Collection) and the correct Data Type (Node or Edge Table).\n",
    "\n",
    "Lets Customize the node style. Lets search with the filter function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets do the same with another table\n",
    "\n",
    "#### MassQL annotation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "tool = 'MassQL'\n",
    "massql_annotations = 'results_download/GNPS2/ea4293bedd5440148267cb201ef7edbc-merged_query_results_MassQL.tsv'\n",
    "df = pd.read_csv(massql_annotations, sep='\\t')\n",
    "print(df.columns)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MassQL table\n",
    "\n",
    "Lets open the MassQL table \n",
    "\n",
    "Original table\n",
    "| charge | filename            | i     | i_norm | scan | ... |\n",
    "|---------------|----------------------------|--------------|---------------|---------------|---------------|\n",
    "| 1        | mzmine_results_iimn_gnps.mgf                       |  125140000.0 | 1.0 | 5051| ... |\n",
    "\n",
    "Prepared table\n",
    "| scan | MassQL_charge | MassQL_filename     | MassQL_i     | MassQL_i_norm | ... |\n",
    "|---------------|----------------------------|--------------|---------------|---------------|--------------|\n",
    "| 5051 | 1         | mzmine_results_iimn_gnps.mgf                         | 125140000.0 | 1.0 | ... |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers function for preparing the annotation table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def detect_separator(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        first_line = file.readline()\n",
    "        if '\\t' in first_line:\n",
    "            return '\\t'\n",
    "        else:\n",
    "            return ','  # Default to comma if no tab found\n",
    "\n",
    "\n",
    "def duplicate_column_if_string_found(df, substring, new_column_name):\n",
    "    # Track if a column was found and duplicated\n",
    "    found_and_duplicated = False\n",
    "\n",
    "    # Loop through all column names in the DataFrame\n",
    "    for col in df.columns:\n",
    "        # Check if the substring matches part of any column name\n",
    "        if substring.lower() in col.lower():  # This makes the search case-insensitive\n",
    "            # Create a new column name by appending the specified new column name\n",
    "            # Duplicate the column\n",
    "            df[new_column_name] = df[col].astype(str).replace('Spectral Match to ', '', regex=True)\n",
    "            print(f\"Column '{col}' duplicated into '{new_column_name}'.\")\n",
    "            found_and_duplicated = True\n",
    "\n",
    "    # If no column matches the substring, print a message\n",
    "    if not found_and_duplicated:\n",
    "        print(f\"No columns found containing the substring '{substring}'.\")\n",
    "\n",
    "\n",
    "def aggregate_columns(series):\n",
    "    # Convert all entries to strings, ensure they are unique and handle NaN values\n",
    "    sorted_values = sorted(series.dropna().astype(str))\n",
    "    aggregated_string = ','.join(sorted(sorted_values))\n",
    "    return aggregated_string\n",
    "\n",
    "\n",
    "def prepare_fbmn_annotation_for_cytoscape(input_file, feature_id_column, tool_prefix, output_suffix='_prep'):\n",
    "    # Load the CSV file into a DataFrame\n",
    "    separator = detect_separator(input_file)\n",
    "    df = pd.read_csv(input_file, sep=separator)\n",
    "\n",
    "    # Drop columns where name contains 'Unnamed'\n",
    "    df = df.loc[:, ~df.columns.str.contains('Unnamed')]\n",
    "\n",
    "    # Identify any column containing 'smiles' in its name, case-insensitively\n",
    "    smiles_columns = [col for col in df.columns if 'smiles' in col.lower()]\n",
    "\n",
    "    # Case insensitive check for 'compound_name' or 'name'\n",
    "    lower_columns = {col.lower(): col for col in df.columns}  # Create a dict with lower case keys and original column names as values\n",
    "    compound_col = lower_columns.get('compound_name', lower_columns.get('name'))\n",
    "\n",
    "\n",
    "    # Check for and remove duplicates based on feature_id_column with either compound_name or smiles\n",
    "    if compound_col:\n",
    "        # Create a combined duplicate check list\n",
    "        for smiles_col in smiles_columns:\n",
    "            # Remove duplicates where the feature ID and either the compound name or one of the smiles columns are the same\n",
    "            initial_row_count = len(df)\n",
    "            df.drop_duplicates(subset=[feature_id_column, compound_col], keep='first', inplace=True)\n",
    "            df.drop_duplicates(subset=[feature_id_column, smiles_col], keep='first', inplace=True)\n",
    "            final_row_count = len(df)\n",
    "            print(f\"Removed {initial_row_count - final_row_count} duplicates based on {feature_id_column}, {compound_col}, and {smiles_col}\")\n",
    "\n",
    "    else:\n",
    "        print(\"Neither 'compound_name' nor 'name' column is present. Checking for duplicates based on SMILES only.\")\n",
    "        for smiles_col in smiles_columns:\n",
    "            initial_row_count = len(df)\n",
    "            df.drop_duplicates(subset=[feature_id_column, smiles_col], keep='first', inplace=True)\n",
    "            final_row_count = len(df)\n",
    "            print(f\"Removed {initial_row_count - final_row_count} duplicates based on {feature_id_column} and {smiles_col}\")\n",
    "\n",
    "    # Check existence of expected columns\n",
    "    expected_cols = ['score', 'adduct', 'mol_formula', 'inchi', 'inchi_key', 'compound_name']\n",
    "    smiles_like_cols = [col for col in df.columns if 'smiles' in col.lower()]\n",
    "    cols_to_aggregate = expected_cols + smiles_like_cols\n",
    "    cols_to_aggregate = [col for col in cols_to_aggregate if col in df.columns]\n",
    "\n",
    "    # If feature_id_column is present and not unique, handle aggregation\n",
    "    if feature_id_column in df.columns:\n",
    "            if not df[feature_id_column].is_unique:\n",
    "                grouped = df.groupby(feature_id_column)[cols_to_aggregate].agg(aggregate_columns).reset_index()\n",
    "                # Drop the original aggregated columns from main DataFrame and merge with aggregated data\n",
    "                df = df.drop(columns=cols_to_aggregate).drop_duplicates(subset=feature_id_column)\n",
    "                df = pd.merge(df, grouped, on=feature_id_column, how='left')\n",
    "                print('Aggregation completed. FeatureID had duplicates.')\n",
    "            else:\n",
    "                print('FeatureID is unique. No aggregation needed.')\n",
    "    else:\n",
    "        raise ValueError(f\"{feature_id_column} is not a column in the DataFrame.\")\n",
    "\n",
    "    # Copy 'smiles' columns with prefixes and keep original\n",
    "    for smiles_column in smiles_columns:\n",
    "        prefixed_smiles_column = f\"{tool_prefix}_{smiles_column}\"\n",
    "        if prefixed_smiles_column not in df.columns:  # Check if prefixed column already exists\n",
    "            df[prefixed_smiles_column] = df[smiles_column]\n",
    "\n",
    "    # Prepare to add prefix to all columns except feature_id_column and original smiles_columns\n",
    "    rename_dict = {}\n",
    "    for col in df.columns:\n",
    "        if col not in smiles_columns and col != feature_id_column and not col.startswith(tool_prefix):\n",
    "            rename_dict[col] = f\"{tool_prefix}_{col}\"\n",
    "\n",
    "    df.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "    # Add an extra column 'annotation_tool' with the value of the tool prefix\n",
    "    df['annotation_tool'] = tool_prefix\n",
    "\n",
    "    duplicate_column_if_string_found(df, 'Compound_name', 'name')\n",
    "\n",
    "    # Renaming and moving feature_id_column to the first position\n",
    "    df = df[[feature_id_column] + [col for col in df.columns if col != feature_id_column]]  # This moves the feature_id_column to the first position\n",
    "\n",
    "    # Special handling if tool are for sirius\n",
    "    if tool_prefix.lower() == 'sir_class':\n",
    "        # Check if necessary columns exist\n",
    "        if 'sir_class_NPC#class' in df.columns and 'sir_class_molecularFormula' in df.columns and 'sir_class_adduct' in df.columns:\n",
    "            df['name'] = df['sir_class_NPC#class'] + ' | ' + df['sir_class_molecularFormula'] + ' | ' + df['sir_class_adduct']\n",
    "        else:\n",
    "            print(\"Required Canopus columns are not all present.\")\n",
    "\n",
    "    elif tool_prefix.lower() == 'sir_struct':\n",
    "        # Check if necessary columns exist\n",
    "        if 'sir_struct_name' in df.columns and 'sir_struct_ConfidenceScore' in df.columns:\n",
    "            df['name'] = df['sir_struct_name'] + ' (' + df['sir_struct_ConfidenceScore'].astype(str) + ')'\n",
    "        else:\n",
    "            print(\"Required Sirius columns are not all present.\")\n",
    "\n",
    "    elif tool_prefix.lower() == 'tima':\n",
    "        # Check if necessary columns exist\n",
    "        if 'tima_candidate_structure_name' in df.columns and 'tima_candidate_structure_tax_npc_03cla' in df.columns:\n",
    "            df['name'] = df['tima_candidate_structure_name'] + ' | ' +df['tima_candidate_structure_tax_npc_03cla']\n",
    "\n",
    "        else:\n",
    "            print(\"Required TIMA columns are not all present.\")\n",
    "\n",
    "        smiles_col = 'tima_candidate_structure_smiles_no_stereo'\n",
    "        if smiles_col in df.columns:\n",
    "            df['smiles'] = df[smiles_col].str.replace('|', ',', regex=False)\n",
    "\n",
    "    # Save the modified DataFrame to a new CSV file with the specified suffix\n",
    "    output_file = f\"{input_file.rsplit('.', 1)[0]}{output_suffix}.tsv\"\n",
    "    df.to_csv(output_file, index=False, sep='\\t')\n",
    "\n",
    "    # Print the new output file name\n",
    "    print(f\"File saved as: {output_file}\")\n",
    "    return df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets process MassQL table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_fbmn_annotation_for_cytoscape(massql_annotations, 'scan', tool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets import MassQL Node Table in Cytoscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets prepare the GNPS table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "tool = 'GNPS'\n",
    "gnps_annotations = 'results_download/GNPS2/861f707d5a4f42e88486c77a4693a38d-merged_results_with_gnps.tsv'\n",
    "df = pd.read_csv(gnps_annotations, sep='\\t')\n",
    "df.columns\n",
    "\n",
    "#We will add a 'tool' prefix to the column and move the 'scan' column to the first position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_fbmn_annotation_for_cytoscape(gnps_annotations, '#Scan#', tool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets prepare the MZmine spectral library annotation table\n",
    "\n",
    "- an `id` column but are not unique -> we can concatenate them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "tool = 'MZmine'\n",
    "mzmine_annotations = 'results_download/mzmine/mzmine_results_annotations.csv'\n",
    "df = pd.read_csv(mzmine_annotations, sep=',')\n",
    "df.columns\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original table\n",
    "| id | compound_name            | adduct    | score | scan | ... |smiles |... |\n",
    "|---------------|----------------------------|--------------|---------------|---------------|---------------|---------------|---------------|\n",
    "| 57        | Nicotinic acid, pyridine-3-carboxylic acid                      | [M+H]+ | 1.0 | 0.975| ... |\tOC(=O)C1=CC=CN=C1 | ... | \n",
    "| 57        | Nicotinic acid, pyridine-3-carboxylic acid                      |  [M+H]+ | 1.0 | 0.975| ... | OC(=O)C1=CC=CN=C1 |... |\n",
    "| 57        | Isonicotinic acid                     |  [M+H]+ | 1.0 | 0.874| ... | c1cnccc1C(=O)O | ... |\n",
    "\n",
    "Prepared table\n",
    "| id | compound_name            | adduct    | score | scan | ... |smiles |... |\n",
    "|---------------|----------------------------|--------------|---------------|---------------|---------------|---------------|---------------|\n",
    "| 57        | Nicotinic acid, pyridine-3-carboxylic acid,  Isonicotinic acid | [M+H]+,[M+H]+ | 1.0, 1.0 | 0.975, 0.874| ... |\tOC(=O)C1=CC=CN=C1,c1cnccc1C(=O)O | ... | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prepare_fbmn_annotation_for_cytoscape(mzmine_annotations, 'id', tool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIRIUS annotations\n",
    "\n",
    "Lets see SIRIUS class and structure annotation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SIRIUS class annnotation\n",
    "\n",
    "There is a 'featureId' column. \n",
    "\n",
    "Lets do some bonus formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = 'sir_class'\n",
    "class_annotations_path = 'results_download/sirius/summary-files/canopus_compound_summary.tsv'\n",
    "pd.read_csv(class_annotations_path, sep= '\\t').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_fbmn_annotation_for_cytoscape(class_annotations_path, 'featureId', tool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SIRIUS structure annotations\n",
    "\n",
    "There is a `feature_id` column. \n",
    "\n",
    "Lets do some bonus formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = 'sir_struct'\n",
    "sirius_annotations_path = 'results_download/sirius/summary-files/compound_identifications.tsv'\n",
    "pd.read_csv(sirius_annotations_path, sep= '\\t').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_fbmn_annotation_for_cytoscape(sirius_annotations_path, 'featureId', tool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TIMA annotations\n",
    "\n",
    "There is a `feature_id` column. \n",
    "\n",
    "Lets do some bonus formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = 'tima'\n",
    "tima_annotations_path = 'results_download/tima/240414_114832_comp_ms_prague/comp_ms_prague_results.tsv'\n",
    "tima_annotations = pd.read_csv(tima_annotations_path, sep='\\t')\n",
    "tima_annotations.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_fbmn_annotation_for_cytoscape(tima_annotations_path, 'feature_id', tool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We continue with Cytoscape\n",
    "\n",
    "Exploration and style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We download all the files for Cytoscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "def zip_prep_files(directory, zip_name, depth=5):\n",
    "    \"\"\"\n",
    "    Search for all files ending in _prep.tsv within the given depth of the directory\n",
    "    and make a zip archive out of them.\n",
    "\n",
    "    :param directory: The directory to search for files in.\n",
    "    :param zip_name: The name of the output zip file.\n",
    "    :param depth: The depth to search for files. If -1, search all levels.\n",
    "                  Depth of 0 means the current directory only,\n",
    "                  1 means the current directory and its immediate subdirectories, and so on.\n",
    "    \"\"\"\n",
    "    def should_include_dir(root_depth, current_depth):\n",
    "        # If depth is negative, no limit is applied.\n",
    "        if depth < 0:\n",
    "            return True\n",
    "        # Include directories within the desired depth.\n",
    "        return (current_depth - root_depth) <= depth\n",
    "\n",
    "    root_depth = directory.count(os.sep)\n",
    "    with zipfile.ZipFile(zip_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for root, dirs, files in os.walk(directory):\n",
    "            current_depth = root.count(os.sep)\n",
    "            if should_include_dir(root_depth, current_depth):\n",
    "                for file in files:\n",
    "                    if file.endswith('_prep.tsv'):\n",
    "                        print(file)\n",
    "                        filepath = os.path.join(root, file)\n",
    "                        zipf.write(filepath, os.path.relpath(filepath, start=directory))\n",
    "                # Modify the dirs in place to avoid unnecessary recursion into subdirectories beyond the depth\n",
    "                if not should_include_dir(root_depth, current_depth + 1):\n",
    "                    dirs.clear()  # This prevents os.walk from going into deeper directories\n",
    "    print(f\"Created zip archive: {zip_name}\")\n",
    "\n",
    "# Example usage:\n",
    "# Provide the directory to search in, the desired zip file name, and the depth\n",
    "# zip_prep_files('/path/to/directory', 'prep_files_archive.zip', depth=1)  # Adjust the depth as needed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_prep_files('results_download', 'cytoscape_input.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "gnps_postprocessing",
   "language": "python",
   "name": "gnps_postprocessing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
